---
title: Learning to Locate Relative Outliers
abstract: Outliers usually spread across regions of low density. However, due to the
  absence or scarcity of outliers, designing a robust detector to sift outliers from
  a given dataset is still very challenging. In this paper, we consider to identify
  relative outliers from the target dataset with respect to another reference dataset
  of normal data. Particularly, we employ Maximum Mean Discrepancy (MMD) for matching
  the distribution between these two datasets and present a novel learning framework
  to learn a relative outlier detector. The learning task is formulated as a Mixed
  Integer Programming (MIP) problem, which is computationally hard. To this end, we
  propose an effective procedure to find a largely violated labeling vector for identifying
  relative outliers from abundant normal patterns, and its convergence is also presented.
  Then, a set of largely violated labeling vectors are combined by multiple kernel
  learning methods to robustly locate relative outliers. Comprehensive empirical studies
  on real-world datasets verify that our proposed relative outlier detection outperforms
  existing methods.
pdf: http://proceedings.pmlr.press/li11/li11.pdf
layout: inproceedings
id: li11
month: 0
firstpage: 47
lastpage: 62
page: 47-62
origpdf: http://jmlr.org/proceedings/papers/v20/li11/li11.pdf
sections: 
author:
- given: S.
  family: Li
- given: I.W.
  family: Tsang
date: 2011-11-17
publisher: PMLR
container-title: Proceedings of the Asian Conference on Machine Learning
volume: '20'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 11
  - 17
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
