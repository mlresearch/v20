---
title: Support Vector Machines Under Adversarial Label Noise
abstract: In adversarial classification tasks like spam filtering and intrusion detection,
  malicious adversaries may manipulate data to thwart the outcome of an automatic
  analysis. Thus, besides achieving good classification performances, machine learning
  algorithms have to be robust against adversarial data manipulation to successfully
  operate in these tasks. While support vector machines (SVMs) have shown to be a
  very successful approach in classification problems, their effectiveness in adversarial
  classification tasks has not been extensively investigated yet. In this paper we
  present a preliminary investigation of the robustness of SVMs against adversarial
  data manipulation. In particular, we assume that the adversary has control over
  some training data, and aims to subvert the SVM learning process. Within this assumption,
  we show that this is indeed possible, and propose a strategy to improve the robustness
  of SVMs to training data manipulation based on a simple kernel matrix correction.
pdf: http://proceedings.mlr.press/v20/biggio11/biggio11.pdf
layout: inproceedings
id: biggio11
month: 0
firstpage: 97
lastpage: 112
page: 97-112
sections: 
author:
- given: B.
  family: Biggio
- given: B.
  family: Nelson
- given: P.
  family: Laskov
date: 2011-11-17
address: South Garden Hotels and Resorts, Taoyuan, Taiwain
publisher: PMLR
container-title: Proceedings of the Asian Conference on Machine Learning
volume: '20'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 11
  - 17
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
