---
title: Robust Generation of Dynamical Patterns in Human Motion by a Deep Belief Nets
abstract: We propose a Deep Belief Net model for robust motion generation, which consists
  of two layers of Restricted Boltzmann Machines (RBMs). The lower layer has multiple
  RBMs for encoding real-valued spatial patterns of motion frames into compact representations.
  The upper layer has one conditional RBM for learning temporal constraints on transitions
  between those compact representations. This separation of spatial and temporal learning
  makes it possible to reproduce many attractive dynamical behaviors such as walking
  by a stable limit cycle, a gait transition by bifurcation, synchronization of limbs
  by phase-locking, and easy top-down control. We trained the model with human motion
  capture data and the results of motion generation are reported here.
pdf: "./sukhbaatar11/sukhbaatar11.pdf"
layout: inproceedings
key: sukhbaatar11
month: 0
firstpage: 231
lastpage: 246
origpdf: http://jmlr.org/proceedings/papers/v20/sukhbaatar11/sukhbaatar11.pdf
sections: 
authors:
- given: S.
  family: Sukhbaatar
- given: T.
  family: Makino
- given: K.
  family: Aihara
- given: T.
  family: Chikayama
---
