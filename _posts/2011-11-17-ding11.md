---
title: Approximate Model Selection for Large Scale LSSVM
abstract: Model selection is critical to least squares support vector machine (LSSVM).
  A major problem of existing model selection approaches of LSSVM is that the inverse
  of the kernel matrix need to be calculated with O(n^3) complexity for each iteration,
  where n is the number of training examples. It is prohibitive for the large scale
  application. In this paper, we propose an approximate approach to model selection
  of LSSVM. We use multilevel circulant matrices to approximate the kernel matrix
  so that the fast Fourier transform (FFT) can be applied to reduce the computational
  cost of matrix inverse. With such approximation, we first design an efficient LSSVM
  algorithm with O(nlog(n)) complexity and theoretically analyze the effect of kernel
  matrix approximation on the decision function of LSSVM. We further show that the
  approximate optimal model produced with the multilevel circulant matrix is consistent
  with the accurate one produced with the original kernel matrix. Under the guarantee
  of consistency, we present an approximate model selection scheme, whose complexity
  is significantly lower than the previous approaches. Experimental results on benchmark
  datasets demonstrate the effectiveness of approximate model selection.
pdf: http://proceedings.mlr.press/v20/ding11/ding11.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: ding11
month: 0
firstpage: 165
lastpage: 180
page: 165-180
sections: 
author:
- given: L.
  family: Ding
- given: S.
  family: Liao
date: 2011-11-17
address: South Garden Hotels and Resorts, Taoyuan, Taiwain
publisher: PMLR
container-title: Proceedings of the Asian Conference on Machine Learning
volume: '20'
genre: inproceedings
issued:
  date-parts:
  - 2011
  - 11
  - 17
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
