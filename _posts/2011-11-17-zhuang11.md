---
title: Unsupervised Multiple Kernel Learning
abstract: 'Traditional multiple kernel learning (MKL) algorithms are essentially supervised
  learning in the sense that the kernel learning task requires the class labels of
  training data. However, class labels may not always be available prior to the kernel
  learning task in some real world scenarios, e.g., an early preprocessing step of
  a classification task or an unsupervised learning task such as dimension reduction.
  In this paper, we investigate a problem of Unsupervised Multiple Kernel Learning
  (UMKL), which does not require class labels of training data as needed in a conventional
  multiple kernel learning task. Since a kernel essentially defines pairwise similarity
  between any two examples, our unsupervised kernel learning method mainly follows
  two intuitive principles: (1) a good kernel should allow every example to be well
  reconstructed from its localized bases weighted by the kernel values; (2) a good
  kernel should induce kernel values that are coincided with the local geometry of
  the data. We formulate the unsupervised multiple kernel learning problem as an optimization
  task and propose an efficient alternating optimization algorithm to solve it. Empirical
  results on both classification and dimension reductions tasks validate the efficacy
  of the proposed UMKL algorithm.'
pdf: "./zhuang11/zhuang11.pdf"
layout: inproceedings
id: zhuang11
month: 0
firstpage: 129
lastpage: 144
page: 129-144
origpdf: http://jmlr.org/proceedings/papers/v20/zhuang11/zhuang11.pdf
sections: 
author:
- given: J.
  family: Zhuang
- given: J.
  family: Wang
- given: S.C.H.
  family: Hoi
- given: X.
  family: Lan
date: '2011-11-17 00:02:09'
publisher: PMLR
---
